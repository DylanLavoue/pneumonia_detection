{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import base librairies\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Import scientific librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# Check running environment\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB=True\n",
    "except:\n",
    "    IN_COLAB=False\n",
    "\n",
    "# Add project directory to kernel paths\n",
    "if IN_COLAB:\n",
    "    print(\"Colab is running!\")\n",
    "    !git clone https://github.com/DylanLavoue/pneumonia_detection.git\n",
    "    sys.path.append('./pneumonia_detection')\n",
    "    \n",
    "else:\n",
    "    print(\"We're running localy\")\n",
    "    sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import custom functions\n",
    "from src.visualization.plot_lib import default_viz\n",
    "from src.data.file_manager import FileManager\n",
    "from src.data.tf_utils import save_image_dataset_to_tfrecord, load_image_dataset_from_tfrecord\n",
    "\n",
    "zoidbergManager = FileManager()\n",
    "\n",
    "# Set default graphics visualization\n",
    "%matplotlib inline\n",
    "default_viz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Transform data into a common dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting any analysis on the data, we just transform the data folder structure into a more convinient one:\n",
    "\n",
    "we remove train, val and set folder as we will split data later\n",
    "we provide 3 folders : one by class\n",
    "This folder is in the interim data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "zoidbergManager.fetch_full_dataset()\n",
    "print('it's ok')\n",
    "is_ok = zoidbergManager.check_full_dataset(print_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will create a DataFrame that contains metadata of each images in orders to analyse those images. Metadata we want to get are :\n",
    "\n",
    "Filename\n",
    "Size of the image\n",
    "Number of channels e.g. grayscale, rbg, rgba, so on\n",
    "Label of the image : normal, virus, bacteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "metadata = []\n",
    "for img_path in Path(zoidbergManager.data_dir / \"interim\" / \"full\").rglob('*.jpeg'):\n",
    "    with Image.open(img_path) as img:\n",
    "        label = img_path.parents[0].name\n",
    "        width, height = img.size\n",
    "        channels = len(img.getbands())\n",
    "        \n",
    "        metadata.append((img_path.name, width, height, channels, label))\n",
    "\n",
    "metadata_df = pd.DataFrame(metadata, columns=[\"image\", \"width\", \"height\", \"channels\", \"label\"])\n",
    "\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Metadata analysis\n",
    "\n",
    "Let's to get some insight by image metadata. We want to know image size and number of channels in order to resize them for CNN. We can also detect some outliers with those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "metadata_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have \n",
    " images, for each of those, we were able to detect its size (width \n",
    " height) and what kind of image it is (Grayscale, RGB, etc...). The numbers of images seems a bit short for deep learning, even if we will use transfer learning. We will probably need data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Size & Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "metadata_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As their size distribution is not peaky, let's plot it in a violin plot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "vp = sns.violinplot(data=metadata_df[['height','width']], orient='h')\n",
    "vp.set_title(\"Distribution of width and height\")\n",
    "vp.set_xlabel(\"Size (# pixels)\", fontsize=10)\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have plot is a violin plot : horizontal box corresponds to quantiles with the mean at the white dot. The colored space is the kernel density of a distribution.\n",
    "According to this violin plot, it appears that we will be able to resize images around \n",
    " without having to oversize too many images (oversizing can create blur in the image so we prefer to avoid it as much as possible).\n",
    "\n",
    "Let's now focus on channels and count how many images have a RGB channel :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(metadata_df['channels'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1    5573\n",
    "3     283\n",
    "Name: channels, dtype: int64\n",
    "So, it turns out that \n",
    " of our dataset is considered to have a RGB, the rest have grayscale color. Let's try to display some of these images to see what they look like :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rgb_channel_df = metadata_df[metadata_df['channels'] == 3].sample(n=10, random_state=42)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5,figsize=(12,5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(rgb_channel_df):\n",
    "        image_name = rgb_channel_df['image'].iloc[i]\n",
    "        image_dir = rgb_channel_df['label'].iloc[i]\n",
    "        image_path = Path(zoidbergManager.data_dir / \"interim\" / \"full\" / image_dir / image_name)\n",
    "        image = Image.open(image_path)\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(image_dir,fontsize=10)\n",
    "        ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is fine, it looks like that they were classified as RGB by the package pyllow but they are indeed black & white pictures. Moreover, as we will transform each image into a RGB scale, it is not really important.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Labels\n",
    "\n",
    "Finally, let's talk about labels. The most important thing we want to know is are there imbalanced classes (i.e if one class has much more data than the others). Class imbalance can make classification more challenging by biasing the model towards the majority class, leading to poor performance on the minority class, and misleading evaluation metrics.\n",
    "Thus, we display histogram for each class :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cp = sns.countplot(data = metadata_df, x='label', width=0.6)\n",
    "cp.set_xlabel('classes')\n",
    "cp.set_ylabel('# instances')\n",
    "sns.despine(offset=10, trim=True)\n",
    "\n",
    "for p in cp.patches:\n",
    "    cp.annotate(str(int(p.get_height())), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bacteria class has roughly twice times more records than normal and virus !\n",
    "So, we need to handle class imbalance. We will do it by :\n",
    "\n",
    "Do not choose the accuracy as metrics but prefer metrics the Matthew correlation coefficient.\n",
    "Set class weights inside our loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. TF dataset & train/test split\n",
    "Once we have completed the data analysis phase, the next step is to prepare data for modeling. Thus, let's split our data into training, validation, and testing sets using TensorFlow, its tf.data library.\n",
    "\n",
    "First, we define some useful hyper-parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img_height = 512\n",
    "img_width = 512\n",
    "channels = \"rgb\"\n",
    "test_split = 0.2\n",
    "val_split = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "We will use the function image_dataset_from_directory to split train and test and load them into tensorflow datasets. We load images in a rgb mode (3 channels) and resize them \n",
    " :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_ds, full_test_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=Path(zoidbergManager.data_dir / \"interim\" / \"full\"),\n",
    "    label_mode=\"categorical\",\n",
    "    color_mode=channels,\n",
    "    batch_size=None,\n",
    "    image_size=(img_height, img_width),\n",
    "    seed=42,\n",
    "    validation_split=test_split,\n",
    "    subset=\"both\"\n",
    ")\n",
    "\n",
    "def count_img_by_class(dataset, class_names=train_ds.class_names):\n",
    "    num_img_by_classes = {name:0 for name in class_names}\n",
    "    for images, labels in dataset:\n",
    "        idx_label = np.nonzero(labels.numpy())[0][0]\n",
    "        for idx, name in enumerate(class_names):\n",
    "            if idx_label == idx:\n",
    "                num_img_by_classes[name] += 1\n",
    "    return num_img_by_classes\n",
    "\n",
    "num_train_img = train_ds.reduce(0, lambda x, _: x + 1).numpy()\n",
    "num_test_img = full_test_ds.reduce(0, lambda x, _: x + 1).numpy()\n",
    "\n",
    "train_img_by_classes = count_img_by_class(train_ds)\n",
    "full_test_img_by_classes = count_img_by_class(full_test_ds)\n",
    "\n",
    "print(\"\\nIn training dataset, there are :\")\n",
    "for class_name, num_img in train_img_by_classes.items():\n",
    "    print(f\"  - {num_img} files for class {class_name}\")    \n",
    "print(\"\\nIn full test dataset, there are :\")\n",
    "for class_name, num_img in full_test_img_by_classes.items():\n",
    "    print(f\"  - {num_img} files for class {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "val_size = int(num_test_img * val_split)\n",
    "\n",
    "full_test_ds.shuffle(buffer_size=num_train_img, seed=42)\n",
    "\n",
    "val_ds = full_test_ds.take(val_size)\n",
    "test_ds = full_test_ds.skip(val_size)\n",
    "\n",
    "val_img_by_classes = count_img_by_class(val_ds)\n",
    "test_img_by_classes = count_img_by_class(test_ds)\n",
    "\n",
    "print(\"In validation dataset, there are :\")\n",
    "for class_name, num_img in val_img_by_classes.items():\n",
    "    print(f\"  - {num_img} files for class {class_name}\")    \n",
    "print(\"\\nIn test dataset, there are :\")\n",
    "for class_name, num_img in test_img_by_classes.items():\n",
    "    print(f\"  - {num_img} files for class {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_path = str(zoidbergManager.data_dir / 'processed' / f'train_{img_height}x{img_width}_{channels}_ds.tfrecord')\n",
    "val_path = str(zoidbergManager.data_dir / 'processed' / f'val_{img_height}x{img_width}_{channels}_ds.tfrecord')\n",
    "test_path = str(zoidbergManager.data_dir / 'processed' / f'test_{img_height}x{img_width}_{channels}_ds.tfrecord')\n",
    "\n",
    "save_image_dataset_to_tfrecord(train_ds, train_path)\n",
    "save_image_dataset_to_tfrecord(val_ds, val_path)\n",
    "save_image_dataset_to_tfrecord(test_ds, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "loaded_val_ds = load_image_dataset_from_tfrecord(val_path)\n",
    "\n",
    "print(\"In loaded validation dataset, there are :\")\n",
    "for class_name, num_img in val_img_by_classes.items():\n",
    "    print(f\"  - {num_img} files for class {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image_val_1, label_val_1 = next(val_ds.take(1).as_numpy_iterator())\n",
    "image_load_val_1, label_load_val_1 = next(loaded_val_ds.take(1).as_numpy_iterator())\n",
    "\n",
    "plt.figure(figsize=(6,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(image_val_1.astype('int64'))\n",
    "plt.title(f'image before tfrecord : {train_ds.class_names[np.nonzero(label_val_1)[0][0]]}')\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(image_load_val_1)\n",
    "plt.title(f'image after tfrecord : {train_ds.class_names[np.nonzero(label_load_val_1)[0][0]]}')\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
